{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import operator\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "MIMIC_3_DIR = '../../data/mimic-3/raw/physionet.org/files/mimiciii/1.4'\n",
    "D_ICD_DIAGNOSES = 'D_ICD_DIAGNOSES.csv.gz'\n",
    "D_ICD_PROCEDURES = 'D_ICD_PROCEDURES.csv.gz'\n",
    "DIAGNOSES_ICD = 'DIAGNOSES_ICD.csv.gz'\n",
    "PROCEDURES_ICD = 'PROCEDURES_ICD.csv.gz'\n",
    "NOTEEVENTS = 'NOTEEVENTS.csv.gz'\n",
    "\n",
    "PREPROCESSED_DIR = '../../data/mimic-3/preprocessed'\n",
    "PREGENERATED_DIR = '../../data/mimic-3/pregenerated'\n",
    "ALL_CODES = 'ALL_CODES.csv'\n",
    "DISCHARGE_SUMMARIES = 'disch_full.csv'\n",
    "ALL_CODES_FILTERED = 'ALL_CODES_filtered.csv'\n",
    "NOTES_LABELED = 'notes_labeled.csv'\n",
    "DISCHARGE_SPLIT_TRAIN = 'disch_train_split.csv'\n",
    "DISCHARGE_SPLIT_DEV = 'disch_dev_split.csv'\n",
    "DISCHARGE_SPLIT_TEST = 'disch_test_split.csv'\n",
    "\n",
    "ICD9_DIR = '../../data/mimic-3/raw_cdc'\n",
    "DIAGNOSES_TABULAR_LIST = 'Dtab12.rtf'\n",
    "PROCEDURES_TABULAR_LIST = 'Ptab12.RTF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICD_Node:\n",
    "    def __init__(\n",
    "        self, \n",
    "        code, \n",
    "        classname='', \n",
    "        short_classname=None,\n",
    "        assignable=False,\n",
    "        parent=None,\n",
    "        **kwarg\n",
    "    ):\n",
    "        self.code = code\n",
    "        self.classname = classname\n",
    "        self.short_classname = short_classname\n",
    "        self.description = []\n",
    "        self.assignable = assignable\n",
    "        self.parent = parent\n",
    "        \n",
    "    def todict(self):\n",
    "        return {\n",
    "            'code' : self.code,\n",
    "            'classname' : self.classname,\n",
    "            'short_classname' : self.short_classname,\n",
    "            'description' : self.description,\n",
    "            'assignable' : self.assignable,\n",
    "            'parent' : self.parent,\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def fromdict(cls, data):\n",
    "        node = cls(**data)\n",
    "        node.description.extend(data['description'])\n",
    "        return node        \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.todict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CATEGORY_REGEX = r'^(\\d+\\.)?\\s?([^a-z]*?)\\s?+\\(([EV\\d\\-]+)\\)$'\n",
    "SUPER_REGEX = r'^([EV]?\\d{2,3})\\s?\\t\\s?([^a-z]{1}.*)'\n",
    "SUB_REGEX = r'^([EV]?\\d{2,3}\\.\\d{1,2})\\s*([^a-z]{1}.*)'\n",
    "# CONTENT_REGEX = r'(Note|Includes|Excludes)\\:\\t?\\s*(.*)'\n",
    "\n",
    "def get_parent_code(code):\n",
    "    code = code[:-1]\n",
    "    if code[-1] == '.':\n",
    "        code = code[:-1]\n",
    "    return code\n",
    "\n",
    "def chunk_data(data, regex):\n",
    "    chunk_ids = [i for i, line in enumerate(data) if re.findall(regex, line)]+[None]\n",
    "    result = []\n",
    "    if chunk_ids:\n",
    "        from_id = chunk_ids[0]\n",
    "        for to_id in chunk_ids[1:]:\n",
    "            sublist = data[from_id:to_id]\n",
    "            result.append(sublist)\n",
    "            from_id = to_id\n",
    "    return result, chunk_ids\n",
    "\n",
    "def get_diagnoses_raw_data():\n",
    "    f = Path(f'{ICD9_DIR}/{DIAGNOSES_TABULAR_LIST}').open()\n",
    "    while True:\n",
    "        line = rtf_to_text(f.readline())\n",
    "        if 'ICD-9-CM Tabular List of Diseases (FY12)' in line:\n",
    "            break\n",
    "    raw_data = [rtf_to_text(line if line[0] != '}' else line[1:]) for line in f.readlines()]\n",
    "    raw_data = ''.join(raw_data).strip().split('\\n')[:-1]\n",
    "    raw_data[0] += ' (000-999)'\n",
    "    raw_data.insert(0, 'CLASSIFICATION OF DIAGNOSIS (000-V99)')\n",
    "    return raw_data\n",
    "\n",
    "def get_procedures_raw_data():\n",
    "    f = Path(f'{ICD9_DIR}/{PROCEDURES_TABULAR_LIST}').open()\n",
    "    while True:\n",
    "        line = rtf_to_text(f.readline())\n",
    "        if 'ICD-9-CM TABULAR LIST OF PROCEDURES (FY12)' in line:\n",
    "            break\n",
    "    raw_data = [rtf_to_text(line if line[0] != '}' else line[1:]) for line in f.readlines()]\n",
    "    raw_data = ''.join(raw_data).strip().split('\\n')[:-1]\n",
    "    raw_data[0] += ' (00-99)'\n",
    "    return raw_data\n",
    "\n",
    "def preprocess_rtf_icd9(is_diag=True):\n",
    "    ### prepare raw data\n",
    "    if is_diag:\n",
    "        raw_data = get_diagnoses_raw_data()\n",
    "    else:\n",
    "        raw_data = get_procedures_raw_data()\n",
    "    \n",
    "    ### chunk data for category classes\n",
    "    category_classes, _ = chunk_data(raw_data, CATEGORY_REGEX)\n",
    "\n",
    "    icd9_dict = dict()\n",
    "    code_stack = []\n",
    "    ### for each category class lines\n",
    "    for cat_lines in category_classes:\n",
    "        ### create category class node\n",
    "        cat_title, *cat_body = cat_lines\n",
    "        _, classname, code = re.findall(CATEGORY_REGEX, cat_title)[0]\n",
    "        node = ICD_Node(code, classname=classname)\n",
    "        \n",
    "        ### chunk data for super classes\n",
    "        super_classes, super_ids = chunk_data(cat_body, SUPER_REGEX)\n",
    "        cat_contents = cat_body[:super_ids[0]] if super_classes else cat_body\n",
    "        ### set category class description\n",
    "        node.description.extend(cat_contents)\n",
    "        \n",
    "        ### set category class parent\n",
    "        startcode, *_ = code.split('-')\n",
    "        if not code_stack:\n",
    "            code_stack.append(code)\n",
    "        else:\n",
    "            while node.parent is None:\n",
    "                tmp_startcode, *tmp_endcode = code_stack[-1].split('-')\n",
    "                if tmp_startcode <= startcode and (tmp_endcode and startcode <= tmp_endcode[0]):\n",
    "                    node.parent = code_stack[-1]\n",
    "                    code_stack.append(code)\n",
    "                else:\n",
    "                    code_stack.pop()\n",
    "    \n",
    "        ### asign category class node\n",
    "        icd9_dict[code] = node\n",
    "        \n",
    "        ### for each super class lines\n",
    "        for super_lines in super_classes:\n",
    "            ### create super class node and set parent\n",
    "            super_title, *super_body = super_lines\n",
    "            super_code, super_classname = re.findall(SUPER_REGEX, super_title.strip())[0]\n",
    "            \n",
    "            if super_code != code:\n",
    "                super_node = ICD_Node(super_code, classname=super_classname)\n",
    "                super_node.parent = node.code\n",
    "            else:\n",
    "                super_node = node\n",
    "                super_node.classname = super_classname\n",
    "            \n",
    "            ### chunk data for sub classes\n",
    "            sub_classes, sub_ids = chunk_data(super_body, SUB_REGEX)\n",
    "            \n",
    "            super_contents = super_body[:sub_ids[0]] if sub_classes else super_body\n",
    "            ### set category class description\n",
    "            super_node.description.extend(super_contents)\n",
    "            \n",
    "            ### asign super class node\n",
    "            icd9_dict[super_code] = super_node\n",
    "            ### for each category class lines\n",
    "            for sub_lines in sub_classes:\n",
    "                ### create category class node\n",
    "                sub_title, *sub_body = sub_lines\n",
    "                sub_code, sub_classname = re.findall(SUB_REGEX, sub_title)[0]\n",
    "                sub_node = ICD_Node(sub_code, classname=sub_classname)\n",
    "                sub_node.description.extend(sub_body)\n",
    "                sub_node.parent = get_parent_code(sub_code)\n",
    "                icd9_dict[sub_code] = sub_node\n",
    "    \n",
    "    if is_diag:\n",
    "        d_icd_filename = D_ICD_DIAGNOSES\n",
    "        ### handle irregulars in diagnoses\n",
    "        category = icd9_dict['V30-V39']\n",
    "        digit_description = dict()\n",
    "        for d in category.description[2:5]:\n",
    "            k, v = d.split('\\t')\n",
    "            digit_description[k] = v\n",
    "        for node in range(30,40):\n",
    "            try:\n",
    "                super_code = f'V{node}'\n",
    "                parent = icd9_dict[super_code]\n",
    "                for d, name in digit_description.items():\n",
    "                    sub_code = f'{parent.code}.{d}'\n",
    "                    sub_classname = f'{parent.classname}, {name}'\n",
    "                    sub_node = ICD_Node(sub_code, \n",
    "                                        classname=sub_classname,\n",
    "                                        parent=parent.code)\n",
    "                    icd9_dict[sub_code] = sub_node\n",
    "            except:\n",
    "                continue  \n",
    "        icd9_dict['719.70'] = ICD_Node( '719.70', \n",
    "                                        classname='Difficulty in walking involving joint site unspecified',\n",
    "                                        assignable=True, \n",
    "                                        parent='719.7')\n",
    "        icd9_dict['719.70'].description=['Deprecated code. Changed to (719.7) in 2003, but exist in mimic-iii.']\n",
    "        \n",
    "    else:\n",
    "        d_icd_filename = D_ICD_PROCEDURES\n",
    "        ### handle irregulars in procedures\n",
    "        icd9_dict['14.8'] = ICD_Node('14.8', classname='Operations On Epiretinal Visual Prosthesis', parent='14')\n",
    "        deprecated_codes = ['36.01', '36.02', '36.05']\n",
    "        deprecated_classname = [\n",
    "            'Single vessel percutaneous transluminal coronary angioplasty [PTCA] or coronary atherectomy without mention of thrombolytic agent', \n",
    "            'Single vessel percutaneous transluminal coronary angioplasty [PTCA] or coronary atherectomy with mention of thrombolytic agent', \n",
    "            'Multiple vessel percutaneous transluminal coronary angioplasty [PTCA] or coronary atherectomy performed during the same operation, with or without mention of thrombolytic agent']\n",
    "        for code, classname in zip(deprecated_codes, deprecated_classname):\n",
    "            icd9_dict[code] = ICD_Node(code, classname=classname, assignable=True, parent='36.0')\n",
    "            icd9_dict[code].description=['Deprecated code. Changed to (00.66) code in 2005, but exist in mimic-iii.']\n",
    "        \n",
    "    converters = {\"ROW_ID\":int, \"ICD9_CODE\":str, \"SHORT_TITLE\":str, \"LONG_TITLE\":str}\n",
    "    icd9_diagnoses_title = pd.read_csv(f'{MIMIC_3_DIR}/{d_icd_filename}', converters=converters)\n",
    "    \n",
    "    for _, data in icd9_diagnoses_title.iterrows():\n",
    "        code = data.ICD9_CODE\n",
    "        code = reformat(code, is_diag)\n",
    "        if code in icd9_dict:\n",
    "            node = icd9_dict[code]\n",
    "        else:\n",
    "            parent_code = get_parent_code(code)\n",
    "            node = ICD_Node(code, \n",
    "                            data.LONG_TITLE,\n",
    "                            parent=parent_code)\n",
    "            \n",
    "        node.classname = data.LONG_TITLE\n",
    "        node.short_classname = data.SHORT_TITLE\n",
    "        node.assignable = True\n",
    "        icd9_dict[code] = node                 \n",
    "        if node.parent not in icd9_dict:\n",
    "            node.parent = get_parent_code(node.parent)\n",
    "\n",
    "    print('DIAGNOSES:' if is_diag else 'PROCEDURES:', len(icd9_dict), 'nodes preprocessed.')\n",
    "    return icd9_dict\n",
    "\n",
    "def reformat(code, is_diag):\n",
    "    if is_diag:\n",
    "        sup_code_len = 4 if code.startswith('E') else 3\n",
    "    else:\n",
    "        sup_code_len = 2\n",
    "    if len(code)>sup_code_len:\n",
    "        i = sup_code_len\n",
    "        sup_code, sub_code = code[:i], code[i:]\n",
    "        code = f'{sup_code}.{sub_code}'\n",
    "    return code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIAGNOSES: 17720 nodes preprocessed.\n",
      "PROCEDURES: 4671 nodes preprocessed.\n",
      "22391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22392/22392 [00:00<00:00, 1117443.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## create icd_9_cm file\n",
    "\n",
    "icd9_diagnoses = preprocess_rtf_icd9(is_diag=True)\n",
    "icd9_procedures = preprocess_rtf_icd9(is_diag=False)\n",
    "print(len(icd9_diagnoses) + len(icd9_procedures))\n",
    "icd9 = dict()\n",
    "icd9['ROOT'] = ICD_Node('ROOT', 'ICD-9-CM')\n",
    "icd9['ROOT'].description.append('ICD-9-CM in MIMIC-III')\n",
    "\n",
    "list(icd9_diagnoses.values())[0].parent = 'ROOT'\n",
    "for v in icd9_diagnoses.values():\n",
    "    v.description.insert(0, '[DIAGNOSE]')\n",
    "icd9.update(icd9_diagnoses)\n",
    "\n",
    "list(icd9_procedures.values())[0].parent = 'ROOT'\n",
    "for v in icd9_procedures.values():\n",
    "    v.description.insert(0, '[PROCEDURE]')\n",
    "icd9.update(icd9_procedures)\n",
    "len(icd9), len([k for k, v in icd9.items() if v.assignable])\n",
    "\n",
    "## hierarchy test\n",
    "hierarchy_nodes = set()\n",
    "for k, v in tqdm(icd9.items()):\n",
    "    if v.assignable:\n",
    "        tmp = v\n",
    "        hierarchy_nodes.add(tmp.code)\n",
    "        while tmp.parent is not None:\n",
    "            tmp = icd9[tmp.parent]\n",
    "            hierarchy_nodes.add(tmp.code)\n",
    "print(len(hierarchy_nodes))\n",
    "\n",
    "f_hierarchy = Path(f'{PREPROCESSED_DIR}/ICD-9-CM.jsonl').open('w')\n",
    "for v in icd9.values():\n",
    "    f_hierarchy.write(f'{json.dumps(v.todict())}\\n')\n",
    "f_hierarchy.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22392"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read icd_9_cm file\n",
    "icd9 = dict()\n",
    "\n",
    "f_hierarchy = Path(f'{PREPROCESSED_DIR}/ICD-9-CM.jsonl').open()\n",
    "while f_hierarchy.readable():\n",
    "    line = f_hierarchy.readline().strip()\n",
    "    if line:\n",
    "        node = ICD_Node.fromdict(json.loads(line))\n",
    "        icd9[node.code] = node\n",
    "    else:\n",
    "        break\n",
    "f_hierarchy.close()\n",
    "len(icd9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = 0\n",
    "max_node = None\n",
    "for k, v in icd9.items():\n",
    "    if v.assignable:\n",
    "        depth = 1\n",
    "        child = v\n",
    "        while child.parent:\n",
    "            child = icd9[child.parent]\n",
    "            depth += 1\n",
    "        if max_depth < depth:\n",
    "            max_depth = depth\n",
    "            max_node = k\n",
    "max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': '290.10', 'classname': 'Presenile dementia, uncomplicated', 'short_classname': 'Presenile dementia', 'description': ['[DIAGNOSE]', 'Presenile dementia:', 'NOS', 'simple type'], 'assignable': True, 'parent': '290.1'}\n",
      "{'code': '290.1', 'classname': 'Presenile dementia', 'short_classname': None, 'description': ['[DIAGNOSE]', 'Brain syndrome with presenile brain disease', 'Excludes:\\tarteriosclerotic dementia (290.40-290.43)', 'dementia associated with other cerebral conditions (294.10-294.11)'], 'assignable': False, 'parent': '290'}\n",
      "{'code': '290', 'classname': 'Dementias', 'short_classname': None, 'description': ['[DIAGNOSE]', 'Code first the associated neurological condition', 'Excludes:\\tdementia due to alcohol (291.0-291.2)', 'dementia due to drugs (292.82)', 'dementia not classified as senile, presenile, or arteriosclerotic (294.10-294.11)', 'psychoses classifiable to 295-298 occurring in the senium without dementia or delirium (295.0-298.8)', 'senility with mental changes of nonpsychotic severity (310.1)', 'transient organic psychotic conditions (293.0-293.9)'], 'assignable': False, 'parent': '290-294'}\n",
      "{'code': '290-294', 'classname': 'ORGANIC PSYCHOTIC CONDITIONS', 'short_classname': None, 'description': ['[DIAGNOSE]', 'Includes:\\tpsychotic organic brain syndrome', 'Excludes:\\tnonpsychotic syndromes of organic etiology (310.0-310.9)', 'psychoses classifiable to 295-298 and without impairment of orientation, comprehension, calculation, learning capacity, and judgement, but associated with physical disease, injury, or condition affecting the brain [e.g., following childbirth] (295.0-298.8)'], 'assignable': False, 'parent': '290-299'}\n",
      "{'code': '290-299', 'classname': 'PSYCHOSES', 'short_classname': None, 'description': ['[DIAGNOSE]', 'Excludes:\\tintellectual disabilities (317-319)'], 'assignable': False, 'parent': '290-319'}\n",
      "{'code': '290-319', 'classname': ' MENTAL, BEHAVIORAL AND NEURODEVELOPMENTAL DISORDERS', 'short_classname': None, 'description': ['[DIAGNOSE]'], 'assignable': False, 'parent': '000-999'}\n",
      "{'code': '000-999', 'classname': 'CLASSIFICATION OF DISEASES AND INJURIES', 'short_classname': None, 'description': ['[DIAGNOSE]'], 'assignable': False, 'parent': '000-V99'}\n",
      "{'code': '000-V99', 'classname': 'CLASSIFICATION OF DIAGNOSIS', 'short_classname': None, 'description': ['[DIAGNOSE]'], 'assignable': False, 'parent': 'ROOT'}\n"
     ]
    }
   ],
   "source": [
    "child = icd9[max_node]\n",
    "while child.parent:\n",
    "    print(child)\n",
    "    child = icd9[child.parent]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['did', 'text', 'labels', 'split']\n",
      "52712\n"
     ]
    }
   ],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "import pyarrow.feather as feather\n",
    "\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNKNOWN_TOKEN = \"<UNK>\"\n",
    "\n",
    "ID_COLUMN = \"_id\"\n",
    "TEXT_COLUMN = \"text\"\n",
    "TARGET_COLUMN = \"target\"\n",
    "SUBJECT_ID_COLUMN = \"subject_id\"\n",
    "code_column_names = [\"icd9_diag\", \"icd9_proc\"]\n",
    "\n",
    "df = feather.read_feather(\n",
    "    \"../../data/mimic-3/medical-coding-reproducibility/mimiciii_clean/mimiciii_clean.feather\",\n",
    "    columns=[\n",
    "        ID_COLUMN,\n",
    "        TEXT_COLUMN,\n",
    "        TARGET_COLUMN,\n",
    "        \"num_words\",\n",
    "        \"num_targets\",\n",
    "    ]\n",
    "    + code_column_names,\n",
    ")\n",
    "splits = feather.read_feather(\n",
    "    # \"../../data/mimic-3/medical-coding-reproducibility/mimiciii_clean/mimiciii_clean_subsplit_0.2.feather\",\n",
    "    \"../../data/mimic-3/medical-coding-reproducibility/mimiciii_clean/mimiciii_clean_splits.feather\"\n",
    ")\n",
    "df = df.merge(splits, on=ID_COLUMN, how=\"inner\")\n",
    "schema = pa.schema(\n",
    "    [\n",
    "        pa.field(ID_COLUMN, pa.int64()),\n",
    "        pa.field(TEXT_COLUMN, pa.large_utf8()),\n",
    "        pa.field(TARGET_COLUMN, pa.list_(pa.large_string())),\n",
    "        pa.field(\"split\", pa.large_string()),\n",
    "        # pa.field(\"num_words\", pa.int64()),\n",
    "        # pa.field(\"num_targets\", pa.int64()),\n",
    "    ]\n",
    ")\n",
    "final_df = pa.Table.from_pandas(\n",
    "    df[\n",
    "        [\n",
    "        ID_COLUMN,\n",
    "        TEXT_COLUMN,\n",
    "        TARGET_COLUMN,\n",
    "        \"split\",\n",
    "        # \"num_words\",\n",
    "        # \"num_targets\",\n",
    "        ]\n",
    "    ], schema=schema)\n",
    "new_names = [\"did\", \"text\", \"labels\", \"split\"]\n",
    "final_df = final_df.rename_columns(new_names)\n",
    "print(final_df.column_names)\n",
    "print(final_df.num_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name = f'{PREGENERATED_DIR}/mimic3_clean_train.jsonl'\n",
    "dev_name = f'{PREGENERATED_DIR}/mimic3_clean_dev.jsonl'\n",
    "test_name = f'{PREGENERATED_DIR}/mimic3_clean_test.jsonl'\n",
    "\n",
    "\n",
    "train_file = Path(train_name).open('w')\n",
    "train_data = final_df.filter(pc.field(\"split\") == \"train\")\n",
    "train_reader = train_data.to_reader(max_chunksize=1)\n",
    "for batch in train_reader:\n",
    "    data = {k:v[0] for k,v in batch.to_pydict().items()}\n",
    "    del data['split']\n",
    "    train_file.write(f\"{json.dumps(data)}\\n\")\n",
    "train_file.close()\n",
    "\n",
    "dev_file = Path(dev_name).open('w')\n",
    "dev_data = final_df.filter(pc.field(\"split\") == \"val\")\n",
    "dev_reader = dev_data.to_reader(max_chunksize=1)\n",
    "for batch in dev_reader:\n",
    "    data = {k:v[0] for k,v in batch.to_pydict().items()}\n",
    "    del data['split']\n",
    "\n",
    "    dev_file.write(f\"{json.dumps(data)}\\n\")\n",
    "dev_file.close()\n",
    "\n",
    "test_file = Path(test_name).open('w')\n",
    "test_data = final_df.filter(pc.field(\"split\") == \"test\")\n",
    "test_reader = test_data.to_reader(max_chunksize=1)\n",
    "for batch in test_reader:\n",
    "    data = {k:v[0] for k,v in batch.to_pydict().items()}\n",
    "    del data['split']\n",
    "\n",
    "    test_file.write(f\"{json.dumps(data)}\\n\")\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681\n"
     ]
    }
   ],
   "source": [
    "## create target_labels file\n",
    "\n",
    "target_labels = set()\n",
    "for target in final_df['labels']:\n",
    "    target_labels.update(target.as_py())\n",
    "print(len(target_labels))\n",
    "\n",
    "f = Path(PREGENERATED_DIR,'target_labels.txt').open('w')\n",
    "for label in list(target_labels):\n",
    "    f.write(label+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5456\n"
     ]
    }
   ],
   "source": [
    "## create simple label\n",
    "labels = set()\n",
    "\n",
    "def update_labels(label):\n",
    "    label_node = icd9[label]\n",
    "    labels.add(label_node.code)\n",
    "    if p:=label_node.parent:\n",
    "        update_labels(p)\n",
    "        \n",
    "for label in target_labels:\n",
    "    update_labels(label)\n",
    "    \n",
    "print(len(labels))\n",
    "\n",
    "f = Path(PREGENERATED_DIR,'labels.txt').open('w')\n",
    "labels = [v for v in icd9.values() if v.code in labels]\n",
    "for label in labels:\n",
    "    f.write(f\"{label.code}\\t{label.classname}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5455"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create pcmap file\n",
    "\n",
    "f = Path(PREGENERATED_DIR,'parent_child_map.txt').open('w')\n",
    "i=0\n",
    "for label in labels:\n",
    "    if label.parent:\n",
    "        i += 1\n",
    "        f.write(f'{label.parent}\\t{label.code}\\n')\n",
    "f.close()\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## create simple label\n",
    "# labels = set()\n",
    "\n",
    "# def update_labels(label):\n",
    "#     label_node = icd9[label]\n",
    "#     labels.add(label_node.code)\n",
    "#     if p:=label_node.parent:\n",
    "#         update_labels(p)\n",
    "        \n",
    "# for label in target_labels:\n",
    "#     update_labels(label)\n",
    "    \n",
    "# print(len(labels))\n",
    "\n",
    "# f = Path(PREGENERATED_DIR,'labels_simple.txt').open('w')\n",
    "# labels = [v for v in icd9.values() if v.code in labels]\n",
    "# for label in labels:\n",
    "#     if '-' not in label.code:\n",
    "#         f.write(f\"{label.code}\\t{label.classname}\\n\")\n",
    "# f.close()\n",
    "\n",
    "# ## create pcmap file\n",
    "\n",
    "# f = Path(PREGENERATED_DIR,'parent_child_map_simple.txt').open('w')\n",
    "# i=0\n",
    "# for label in labels:\n",
    "#     if '-' not in label.code:\n",
    "#         i += 1\n",
    "#         if label.parent:\n",
    "#             if '-' in label.parent:\n",
    "#                 f.write(f'ROOT\\t{label.code}\\n')\n",
    "#             else:\n",
    "#                 f.write(f'{label.parent}\\t{label.code}\\n')\n",
    "# f.close()\n",
    "# i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
